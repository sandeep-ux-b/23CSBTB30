{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnaJ6dxALpY0am9Lgaav1l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sandeep-ux-b/23CSBTB30/blob/main/Lab09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqwNEF2QjZdn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "df = pd.read_csv('loan_data.csv')\n",
        "df.info()\n",
        "df.describe()\n",
        "df.head()\n",
        "print(\"Breakup of credit approval status.\\n1 means approved credit,\\n0 means not approved.\")\n",
        "print(df['credit.policy'].value_counts())\n",
        "print(f\"Top 5 criteria for Loan Approval:\\n{df['purpose'].value_counts()}\")\n",
        "print(f\"Top 5 Int.Rates for Loan Approval:\\n{df['int.rate'].value_counts()}\")\n",
        "df[df['credit.policy']==1]['fico'].plot.hist(bins=30,\n",
        "                                             alpha=0.5,color='blue',\n",
        "                                             label='Credit.Policy=1')\n",
        "\n",
        "df[df['credit.policy']==0]['fico'].plot.hist(bins=30,\n",
        "                                             alpha=0.5, color='red',\n",
        "                                             label='Credit.Policy=0')\n",
        "plt.legend(fontsize=15)\n",
        "plt.title (\"Histogram of FICO score based credit policies\", fontsize=16)\n",
        "plt.xlabel(\"FICO score\", fontsize=14)\n",
        "sns.boxplot(x=df['credit.policy'],y=df['int.rate'])\n",
        "plt.title(\"Interest rate varies between risky and non-risky borrowers\", fontsize=15)\n",
        "plt.xlabel(\"Credit policy\",fontsize=15)\n",
        "plt.ylabel(\"Interest rate\",fontsize=15)\n",
        "sns.boxplot(x=df['credit.policy'],y=df['log.annual.inc'])\n",
        "plt.title(\"Income level does not make a big difference in\\ncredit approval odds\", fontsize=15)\n",
        "plt.xlabel(\"Credit policy\",fontsize=15)\n",
        "plt.ylabel(\"Log. annual income\",fontsize=15)\n",
        "sns.boxplot(x=df['credit.policy'],y=df['days.with.cr.line'])\n",
        "plt.title(\"Credit-approved users have a slightly higher days with credit line\", fontsize=15)\n",
        "plt.xlabel(\"Credit policy\",fontsize=15)\n",
        "plt.ylabel(\"Days with credit line\",fontsize=15)\n",
        "sns.boxplot(x=df['credit.policy'],y=df['dti'])\n",
        "plt.title(\"Debt-to-income level does not make a big difference in credit approval odds\", fontsize=15)\n",
        "plt.xlabel(\"Credit policy\",fontsize=15)\n",
        "plt.ylabel(\"Debt-to-income ratio\",fontsize=15)\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.countplot(x='purpose',hue='not.fully.paid',data=df, palette='Set1')\n",
        "plt.title(\"Bar chart of loan purpose colored by not fully paid status\", fontsize=17)\n",
        "plt.xlabel(\"Purpose\", fontsize=15)\n",
        "sns.jointplot(x='fico',y='credit.policy',data=df, color='purple', size=12)\n",
        "plt.figure(figsize=(14,7))\n",
        "sns.lmplot(y='int.rate',x='fico',data=df,hue='credit.policy',\n",
        "           col='not.fully.paid',palette='Set1',size=6)\n",
        "df_final = pd.get_dummies(df,['purpose'],drop_first=True)\n",
        "df.shape, df_final.shape, df_final.columns[14:]\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dtree = DecisionTreeClassifier(criterion='log_loss',max_depth=None)\n",
        "dtree.fit(X_train,y_train)\n",
        "train_pred  = dtree.predict(X_train)\n",
        "predictions = dtree.predict(X_test)\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "print(f\"Accuracy of Train:{accuracy_score(y_train,train_pred)}\")\n",
        "print(f\"Accuracy of Test:{accuracy_score(y_test,predictions)}\")\n",
        "print(classification_report(y_test,predictions))\n",
        "cm=confusion_matrix(y_test,predictions)\n",
        "print(cm)\n",
        "print (\"Accuracy of prediction:\",round((cm[0,0]+cm[1,1])/cm.sum(),3))\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc = RandomForestClassifier(n_estimators=1000)\n",
        "rfc.fit(X_train, y_train)\n",
        "rfc_train_pred = rfc.predict(X_train)\n",
        "rfc_test_pred = rfc.predict(X_test)\n",
        "print(f\"Accuracy of Train:{accuracy_score(y_train,rfc_train_pred)}\")\n",
        "print(f\"Accuracy of Test:{accuracy_score(y_test,rfc_test_pred)}\")\n",
        "cr = classification_report(y_test,predictions)\n",
        "print(cr)\n",
        "cm = confusion_matrix(y_test,rfc_pred)\n",
        "print(cm)\n",
        "nsimu = 21\n",
        "accuracy=[0]*nsimu\n",
        "ntree = [0]*nsimu\n",
        "for i in range(1,nsimu):\n",
        "    rfc = RandomForestClassifier(n_estimators=i*5,min_samples_split=10,max_depth=None,criterion='gini')\n",
        "    rfc.fit(X_train, y_train)\n",
        "    rfc_pred = rfc.predict(X_test)\n",
        "    cm = confusion_matrix(y_test,rfc_pred)\n",
        "    accuracy[i] = (cm[0,0]+cm[1,1])/cm.sum()\n",
        "    ntree[i]=i*5\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(x=ntree[1:nsimu],y=accuracy[1:nsimu],s=60,c='red')\n",
        "plt.title(\"Number of trees in the Random Forest vs. prediction accuracy (criterion: 'gini')\", fontsize=18)\n",
        "plt.xlabel(\"Number of trees\", fontsize=15)\n",
        "plt.ylabel(\"Prediction accuracy from confusion matrix\", fontsize=15)\n",
        "nsimu = 21\n",
        "accuracy=[0]*nsimu\n",
        "ntree = [0]*nsimu\n",
        "for i in range(1,nsimu):\n",
        "    rfc = RandomForestClassifier(n_estimators=i*5,min_samples_split=10,max_depth=None,criterion='entropy')\n",
        "    rfc.fit(X_train, y_train)\n",
        "    rfc_pred = rfc.predict(X_test)\n",
        "    cm = confusion_matrix(y_test,rfc_pred)\n",
        "    accuracy[i] = (cm[0,0]+cm[1,1])/cm.sum()\n",
        "    ntree[i]=i*5\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(x=ntree[1:nsimu],y=accuracy[1:nsimu],s=60,c='red')\n",
        "plt.title(\"Number of trees in the Random Forest vs. prediction accuracy (criterion: 'entropy')\", fontsize=18)\n",
        "plt.xlabel(\"Number of trees\", fontsize=15)\n",
        "plt.ylabel(\"Prediction accuracy from confusion matrix\", fontsize=15)\n",
        "nsimu = 21\n",
        "accuracy=[0]*nsimu\n",
        "ntree = [0]*nsimu\n",
        "for i in range(1,nsimu):\n",
        "    rfc = RandomForestClassifier(n_estimators=i*5,min_samples_split=10,max_depth=None,criterion='gini')\n",
        "    rfc.fit(X_train, y_train)\n",
        "    rfc_pred = rfc.predict(X_test)\n",
        "    cm = confusion_matrix(y_test,rfc_pred)\n",
        "    accuracy[i] = (cm[0,0]+cm[1,1])/cm.sum()\n",
        "    ntree[i]=i*5\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(x=ntree[1:nsimu],y=accuracy[1:nsimu],s=60,c='red')\n",
        "plt.title(\"Number of trees in the Random Forest vs. prediction accuracy (max depth: None)\", fontsize=18)\n",
        "plt.xlabel(\"Number of trees\", fontsize=15)\n",
        "plt.ylabel(\"Prediction accuracy from confusion matrix\", fontsize=15)\n",
        "nsimu = 21\n",
        "accuracy=[0]*nsimu\n",
        "ntree = [0]*nsimu\n",
        "for i in range(1,nsimu):\n",
        "    rfc = RandomForestClassifier(n_estimators=i*5,min_samples_split=2,max_depth=None,criterion='gini')\n",
        "    rfc.fit(X_train, y_train)\n",
        "    rfc_pred = rfc.predict(X_test)\n",
        "    cm = confusion_matrix(y_test,rfc_pred)\n",
        "    accuracy[i] = (cm[0,0]+cm[1,1])/cm.sum()\n",
        "    ntree[i]=i*5\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(x=ntree[1:nsimu],y=accuracy[1:nsimu],s=60,c='red')\n",
        "plt.title(\"Number of trees in the Random Forest vs. prediction accuracy (minimum sample split: 2)\", fontsize=18)\n",
        "plt.xlabel(\"Number of trees\", fontsize=15)\n",
        "plt.ylabel(\"Prediction accuracy from confusion matrix\", fontsize=15)\n",
        "nsimu = 21\n",
        "accuracy=[0]*nsimu\n",
        "ntree = [0]*nsimu\n",
        "for i in range(1,nsimu):\n",
        "    rfc = RandomForestClassifier(n_estimators=i*5,min_samples_split=20,max_depth=None,criterion='gini')\n",
        "    rfc.fit(X_train, y_train)\n",
        "    rfc_pred = rfc.predict(X_test)\n",
        "    cm = confusion_matrix(y_test,rfc_pred)\n",
        "    accuracy[i] = (cm[0,0]+cm[1,1])/cm.sum()\n",
        "    ntree[i]=i*5\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(x=ntree[1:nsimu],y=accuracy[1:nsimu],s=60,c='red')\n",
        "plt.title(\"Number of trees in the Random Forest vs. prediction accuracy (minimum sample split: 20)\", fontsize=18)\n",
        "plt.xlabel(\"Number of trees\", fontsize=15)\n",
        "plt.ylabel(\"Prediction accuracy from confusion matrix\", fontsize=15"
      ]
    }
  ]
}